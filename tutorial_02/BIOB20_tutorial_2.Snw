\documentclass[a4paper]{article}

% Packages.
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{color}
\usepackage[answerdelayed]{exercise}
\usepackage{url}

% Bibliography.
\bibliographystyle{abbrv}

% Definitions.
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% Exercise layout.
\renewcommand{\ExerciseHeader}{\par\noindent\textbf{\large
\ExerciseName\ \ExerciseHeaderNB\ExerciseHeaderTitle
\ExerciseHeaderOrigin}\par}

\renewcommand{\AnswerHeader}{\par\noindent\textbf{
Answer to Question \ExerciseHeaderNB}\par}
%Answer to \ExerciseName\ \ExerciseHeaderNB}\par}

\setlength{\ExerciseSkipAfter}{3mm}

% Document layout.
\setlength{\oddsidemargin}{18pt}
\setlength{\textwidth}{420pt}
\setlength{\marginparwidth}{0pt}
\setlength{\marginparsep}{0pt}

% Options.
\SweaveOpts{keep.source=TRUE}

\title{The binomial distribution}
\author{}
\date{}


\begin{document}
\maketitle

\section{Overview}

In this chapter we introduce the notion of level of a statistical test. We
also explain how to create variables with a binomial distribution and how
to design statistical tests with binomial variables. We use the framework
of formal Mendelian genetics to give an example of application.


\section{The problem}

In 1913, an undergraduate student named Alfred H. Sturtevant published one
of the most influential scientific discoveries in genetics
\cite{sturtevant1913linear}. He was working on fruit flies in the
laboratory of Thomas H. Morgan who had just figured out the rules of
inheritance for genes on the X chromosome.

Back then, scientists knew that genes were on chromosomes, but they had no
idea what they were made of --- the fact that it is DNA would come only in
1944~\cite{avery1944studies}. Yet, Sturtevant found a way to map the genes
relative to each other. It is astonishing that we knew the order of genes
on the chromosomes way before we understood what they were.

The development of statistics came substantially later, so Sturtevant did
not perform tests or investigate the confidence levels of his estimations.
We will use R to view his results in the light of modern statistics.


\section{The binomial distribution}

Fruit flies found in the wild have a black body and red eyes. Sturtevant
had access to mutants with a yellow body or with bright red ``vermilion''
eyes. He knew that the mutated genes were on the X chromosome in both
cases.

We will denote the allele for a black body $b^0$, and the allele for a
yellow body $b^1$. Likewise, we will denote the allele for red eyes $r^0$,
and the allele for vermilion eyes $r^1$. In one of his experiments,
Sturtevant crossed heterozygous females $b^0/b^1$ and looked at the
phenotype of the males in the progeny. Males have only one X chromosome,
which they do not pass to their sons (they pass their Y chromosome
instead), so in this case the genotype of the father is irrelevant. The
alleles on the X chromosome in the male progeny always come from the
mother.

\begin{center}
\includegraphics[width=40mm]{first_cross.pdf}
\end{center}

Among the 1084 males in the progeny of the crosses, 571 were black and 513
were yellow. From this, Sturtevant concluded that males were equally
likely to receive the $b^0$ or the $b^1$ allele from their mother.

To test whether this is indeed the case, we will need a new type of random
variable.

\begin{definition}[binomial distribution]
A binary event has exactly two possible outcomes that are labelled 0 and
1. The binomial distribution describes the total number of 1s in a series
of binary events that are independent and that have the same probability.
The binomial distribution is usually represented by the symbol $B(n,p)$,
where $n$ is the number of events (sometimes referred to as the size) and
$p$ is their probability.
\end{definition}

We will not need the formula, but a variable $X$ follows the binomial
distribution $B(n,p)$ if and only if the probability that $X$ takes the
value $k$ is given by the expression
\begin{equation}
\label{formula}
P(X = k) = \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k} \;\;\; (k=0,1,\ldots, n).
\end{equation}

We are thus interested in generating samples from the distribution
$B(1084, 1/2)$ because there are 1084 events in total and the alleles
$b^0$ and $b^1$ are assumed to have the same probability 1/2.


\begin{Exercise}[name=Question]
Using the documentation if necessary, produce one random number from
$B(1084, 1/2)$ using the function \texttt{rbinom(...)}.
\par\noindent\textcolor{Blue}{\textbf{Note:} the $n$ in $B(n,p)$ is the
parameter \texttt{size} of the \texttt{rbinom(...)} function.}
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
rbinom(n=1, size=1084, prob=1/2)
@
\end{Answer}


\begin{Exercise}[name=Question]
Produce 100,000 random numbers from $B(1084, 1/2)$ using the function
\texttt{rbinom(...)} and compute the average.
\end{Exercise}
\begin{Answer}
% 0.1%-99.9 quantiles from 10,000 replications: 541.842--542.165
<< >>=
set.seed(123)
mean(rbinom(n=100000, size=1084, prob=1/2))
@
\end{Answer}


\section{Analyses with one gene}

Now that we can easily produce samples from the target distribution, we
can use a standard statistical analysis to test whether the alleles $b^0$
and $b^1$ are equally probable. To this end, we need
\begin{enumerate}
\item
A null hypothesis.
\item
An alternative  hypothesis.
\item
A protocol to collect data.
\item
A test statistic.
\item
A decision rule.
\end{enumerate}


\begin{Exercise}[name=Question]
What are the null and the alternative hypotheses?
\end{Exercise}
\begin{Answer}
The number of $b^0$ alleles, say, is assumed to be drawn from the binomial
distribution $B(1084, p)$. The null hypothesis is that $p = 1/2$ and the
alternative hypothesis is that $p\neq 1/2$.
\par\noindent\textcolor{Blue}{\textbf{Note:} the alternative is \emph{not}
that the null hypothesis is false. It is more specific.}
\end{Answer}


The protocol to collect the data was given by Sturtevant in
reference~\cite{sturtevant1913linear}. Here we will simply assume that he
followed the principles of unbiased data collection and we will not look
further into this.

Our statistic will be the absolute difference between the observed number
of $b^0$ alleles and their expected value ($1084 / 2 = 542$ in this case).
By taking the absolute value, the score is low if the null hypothesis is
true, and high if it is false. With this simple trick, the null hypothesis
allows us to make predictions about the magnitude of the score.

To find a quantitative decision rule, we need to find out more about the
distribution of the statistic when the null hypothesis is true.

\begin{Exercise}[name=Question]
Produce a random sample of size 1 from $B(1084, 1/2)$ using the function
\texttt{rbinom(...)} and compute the value of the statistic on this sample
using the function \texttt{abs(...)} to take the absolute value.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
abs(rbinom(n=1, size=1084, prob=1/2) - 542)
@
\end{Answer}


\begin{Exercise}[name=Question]
Produce 100,000 random values of the statistic under the null
distribution. Store them in a variable called \texttt{nulld} (this stands
for ``null distribution''). Use the function \texttt{mean(...)} to compute
the approximate expected value of the statistic under the null hypothesis.
\end{Exercise}
\begin{Answer}
% 0.1%-99.9 quantiles from 10,000 replications: 13.033--13.238
<< >>=
set.seed(123)
nulld <- abs(rbinom(n=100000, size=1084, prob=1/2) - 542)
mean(nulld)
@
\end{Answer}


The average gives us an idea of the typical value of the score when the
null hypothesis is true. But to make a decision rule we need to know which
values are atypical, so that we can confidently reject the null hypothesis
when the score is too large to be explained by chance.


\begin{Exercise}[name=Question]
Plot the histogram of the vector \texttt{nulld} using the function
\texttt{hist(...)} with default parameters.
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
hist(nulld)
@
\end{Answer}


In order to design formal decision rules, we need to measure risks. One of
the key concepts is the so-called level of a test.

\begin{definition}[level of a statistical test]
The level of a statistical test is the risk of falsely rejecting the null
hypothesis. In other words, it is the probability of rejecting the null
hypothesis when it is true. The level is chosen by the analyst.
\end{definition}

The level is a risk that the analyst is willing to take, so the value is
typically small, like 1\% or so. If the level is chosen by the analyst,
then why not choose a 0\% risk? We will see later, when we discuss the
notion of power of a statistical test, that there is a cost to lowering
the level. Without going into technical considerations, we will set the
level to 1\% for the present analysis.

\begin{Exercise}[name=Question]
What is the cutoff value $x$ such that there is only a 1\% chance that the
statistic is greater than or equal to $x$ when the null hypothesis is
true? Add a red vertical line at this value in the plot of the histogram.
\end{Exercise}
\begin{Answer}
% 0.1%-99.9 quantiles from 10,000 replications: 42--43 (included).
<< fig=TRUE >>=
quantile(nulld, 0.99)
hist(nulld)
abline(v=quantile(nulld, 0.99), col="red")
@
\end{Answer}


Having chosen a level, we now have a threshold for the decision rule and
we can decide whether we believe the null hypothesis or not.

\begin{Exercise}[name=Question]
Finish the statistical analysis and conclude about the null hypothesis.
\end{Exercise}
\begin{Answer}
The value $x$ at the top 1\% of the null distribution \texttt{nulld} is
approximately 42. This means that if the null hypothesis is true, there is
an approximately 1\% chance that the statistic is below 542 - 42 = 500 or
higher than 542 + 42 = 584. Sturtevant obtained 571 $b^0$ alleles, which
is within the interval 500--584, so there is no reason to reject the null
hypothesis. The results are compatible with expectations.

A more automatic way of concluding is to note that the observed value of
the statistic is $|571 - 542| = 29 < 42$. The value 29 is on the
\emph{left} or the red line in the histogram of the null distribution.
This kind of statement is in general sufficient to accept the null
hypothesis.
\end{Answer}


Sturtevant then focused on the color of the eyes in the same cross. The
females were heterozygous $r^0/r^1$, and once again the genotype of the
fathers was irrelevant because he considered only the males in the
progeny. Sturtevant obtained 574 males with red eyes and 510 males with
vermilion eyes.

\begin{center}
\includegraphics[width=40mm]{second_cross.pdf}
\end{center}

\begin{Exercise}[name=Question]
Perform a similar statistical analysis to decide whether the alleles
$r^0$ and $r^1$ are equally probable.
\end{Exercise}
\begin{Answer}
The null hypothesis, the alternative hypothesis, the data collection
protocol, the statistic and the decision rule are the same. In this case
the null distribution is also the same, so we can conclude directly. The
observed statistic is $|574 - 542| = 32 < 42$ (the value is on the
\emph{left} of the red line in the histogram) so we accept the null
hypothesis.
\end{Answer}


\section{Analyses with two genes}

Sturtevant actually recorded both characters simultaneously for every
male. Out of the 1084 males in the progeny of the cross above, 385 were
black with red eyes ($b^0, r^0$), 186 were black with vermilion eyes
($b^0, r^1$), 189 were yellow with red eyes ($b^1, r^0$) and 324 were
yellow with vermilion eyes ($b^1, r^1$).

\begin{center}
\includegraphics[width=60mm]{third_cross.pdf}
\end{center}

Sturtevant knew that in the 1865 landmark work of Gregor Mendel, it was
shown that characters are inherited
independently~\cite{mendel1866versuche} (an English translation is
available in reference~\cite{mendel1996experiments}). But Gregor Mendel
did not know that genes are on chromosomes and Sturtevant was interested
in testing whether characters were inherted independently even when they
are on the same chromsome.

\begin{definition}[independence]
In statistics, two events are independent if the probability that they
both occur is the product of the probabilities that each one occurs
individually. Mathematically, $A$ and $B$ are two independent events if
and only if  $\text{Prob}(A\cap B) = \text{Prob}(A) \text{Prob}(B)$.
\end{definition}

Since the frequency of the allele $b^0$ is 1/2 and that of the allele
$r^0$ is also 1/2, the frequency of the genotype $b^0, r^0$ should be $1/2
\times 1/2 = 1/4$ if the alleles are inherited independently. In other
words, the number of genotypes $b^0, r^0$ should be distributed as
$B(1084, 1/4)$.


\begin{Exercise}[name=Question]
In this context, what are the null and the alternative hypotheses?
What statistic should we use to discriminate the null from the alternative
hypothesis?
\end{Exercise}
\begin{Answer}
The number of genotypes $b^0, r^0$ is assumed to be drawn from the
binomial distribution $B(1084, p)$. The null hypothesis is that $p = 1/4$
and the alternative hypothesis is that $p\neq 1/4$.

The expected value is no longer 542 but 271. We should now compute the
deviation from 271.
\end{Answer}


\begin{Exercise}[name=Question]
\label{exnulld_pair}
Produce 100,000 random values of the statistic under the null
distribution. Store them in a variable called \texttt{nulld}. Plot the
histogram of the vector \texttt{nulld} using the function
\texttt{hist(...)} with default parameters.
\end{Exercise}
\begin{Answer}
% 0.1%-99.9 quantiles from 10,000 replications: 36--37 (included).
<< fig=TRUE >>=
set.seed(123)
nulld <- abs(rbinom(n=100000, size=1084, prob=1/4) - 271)
hist(nulld)
@
\end{Answer}


\begin{Exercise}[name=Question]
What is the cutoff value $x$ such that there is only a 1\% chance that the
statistic is greater than or equal to $x$? Add a red vertical line at this
value in the plot of the histogram.
\end{Exercise}
\begin{Answer}
<< >>=
quantile(nulld, 0.99)
hist(nulld)
abline(v=quantile(nulld, 0.99), col="red")
@
\end{Answer}


\begin{Exercise}[name=Question]
Finish the statistical analysis and conclude about the null hypothesis.
\end{Exercise}
\begin{Answer}
The observed statistic is $|385 - 271| = 114 > 36$. This value is higher
than the threshold so we reject the null hypothesis (it is on the
\emph{right} of the red line in the histogram). We conclude that the
probability of ocurrence of $b^0, r^0$ is not 1/4 so the two alleles are
not inherited independently.
\end{Answer}


\section{Estimating the linkage}

Sturtevant went further than observing that genes were not inherited
independently. He also used the probability of association between the
alleles as a distance between the corresponding genes.

In his footsteps, we set out to estimate the probability of occurrence of
the genotype $b^0, r^0$. For this, we can use the maximum likelihood
method, whereby we screen hypotheses and pick the one where the observed
events are the most probable.

\begin{center}
\includegraphics[width=71mm]{maximum_likelihood.pdf}
\end{center}

The likelihood is just the probability of the observations. The parameter
is the quantity to estimate. The principle of maximum likelihood
estimation is to pick the value of the parameter such that the likelihood
reaches its maximum. This is the value for which the events that happened
were the most plausible, or most likely to occur.

This is a very deep idea. It says that given two scenarios, we should give
preference to the one where reality involves fewer improbable events. This
is a general principle of science, sometimes referred to as Occam's razor.

Going back to the problem at hand, we start with a coarse approach where
we test a select few values of interest and pick the best option among
them. But first, we need to introduce a useful way of counting values in
vectors.

The operator \texttt{==} (two equals signs in a row) is used for testing
(it should not be confused with a single equals sign, that is used for
assignment). It is convenient to combine the \texttt{==} operator with the
function \texttt{sum(...)} to count how many occurrences of a certain
value are in a given vector. Below is an example.

<< >>=
x <- c(0, 1, 1, 1, 0 ,0, 1)
sum(x == 1)
@

\begin{Exercise}[name=Question]
\label{exnulld_pair}
Produce 100,000 random values from the distribution $B(1084, 1/4)$. How
many times does the value 385 appear in the output?
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=1/4) == 385)
@
\end{Answer}


\begin{Exercise}[name=Question]
Repeat the procedure of Question~\ref{exnulld_pair} by setting
\texttt{prob} to 0.30, 0.35, 0.40 and 0.45. Which is the value of
\texttt{prob} such that 385 appears most frequently in the output?
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=0.30) == 385)
sum(rbinom(n=100000, size=1084, prob=0.35) == 385)
sum(rbinom(n=100000, size=1084, prob=0.40) == 385)
sum(rbinom(n=100000, size=1084, prob=0.45) == 385)
# The highest is reached for prob = 0.35.
@
\end{Answer}


We should favor the distribution $B(1084, p)$ where the observed value
(\textit{i.e.}, 385) is as common as possible. Other distributions should
be ignored because the observations were less likely to occur.


\section{Bonus points: the likelihood curve}

The function \texttt{dbinom(...)} gives the probability of observing a
result under a given binomial distribution. It is the numeric application
of equation~(\ref{formula}), \textit{i.e.}, unlike \texttt{rbinom(...)} it
is a deterministic function.

\begin{Exercise}[name=Question]
Using the documentation if necessary, compute the probability that the
distribution $B(1084, 0.35)$ produces the observation 385.
\end{Exercise}
\begin{Answer}
<< >>=
dbinom(x=385, size=1084, prob=0.35)
@
\end{Answer}


This approach gives almost the same result as simulations with 100,000
replications. The simulations are inexact because of the random sampling,
but for large samples, they approach the correct result.


The function \texttt{seq(...)} creates a regular sequence of values. Let
us create a vector with values $0.300, 0.305, 0.3100, \ldots  0.40$ and
call it \texttt{p} as in $B(n,p)$.

<< >>=
p <- seq(from=0.3, to=.4, by=.005)
@

We are now ready to test multiple values of the parameter $p$ of the
binomial distribution and see for which value we are most likely to
observe 385 genotypes $b^0,r^0$.


\begin{Exercise}[name=Question]
Use the functions \texttt{dbinom(...)} and \texttt{seq(...)} as above to
return the probability of obtaining 385 when $p = 0.300, 0.305, \ldots
0.40$. Assign the results to a variable called \texttt{likelihood}. Plot
the likelihood with the command \texttt{plot(p, likelihood, type="l",
panel.first=grid())}. For which value of \texttt{p} does the curve reach
its heighest point?
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
likelihood <- dbinom(x=385, size=1084, prob=p)
plot(p, likelihood, type="l", panel.first=grid())
# Add a red vertical line at position p = .355
abline(v=.355, col="red")
@
\end{Answer}


%The highest value of the likelihood is of little relevance. What matters
%is the value of $p$ for which the maximum is reached. It is interesting to
%get the answer graphically. The R programming language makes it easy to
%create figures from which further insight can be gained. Run the following
%command to plot the likelihood against the value of $p$ in the
%distribution $B(1084, p)$.
%<< eval=FALSE, echo=TRUE >>=
%plot(x=p, y=likelihood, type="l")
%@
%
%
%\begin{Exercise}[name=Question]
%What is the maximum likelihood estimate of $p$?
%\par\noindent\textcolor{Blue}{\textbf{Note:} you can use the argument
%\texttt{panel.first=grid()} in \texttt{plot(...)} for more precision.}
%\end{Exercise}
%\begin{Answer}
%The maximum is reached for $p=0.355$.
%<< fig=TRUE >>=
%plot(p, likelihood, type="l", panel.first=grid())
%@
%\end{Answer}
%
%
%\section{Bonus points: the Bayesian approach}
%
%Plotting the likelihood function brings us one step closer to being able
%to comment on the confidence in our estimate $p=0.355$. Indeed, we can see
%that the likelihood drops by a factor 10 or more for values outside the
%interval 0.325--0.385. This means that the values of $p$ outside this
%interval are at least 10 times less likely to produce the observed outcome
%385 males with genotype $b^0,r^0$ than $p=0.355$.
%
%But this is not the same as saying that values of $p$ outside the interval
%are 10 times less plausible than $p=0.355$. Actually, if you are a
%frequentist, this last statement does not mean anything at all because $p$
%is not a random variable. It is the unknown linkage between the alleles
%$b^0$ and $r^0$, which is a value fixed by nature.
%
%The most intuitive way to quantify the uncertainty about our estimate of
%$p$ is to use a Bayesian approach, with the caveat that the answer is
%influenced by our prior beliefs. We can say that we had no preconception
%and we believed that all the possible values between 0 and 1 were equally
%plausible (specifying a prior belief based on the conclusion of Gregor Mendel
%that the value is 1/4 turns out to be more difficult).
%
%Once again, it is useful to refer to the graphical representation of the
%approach.
%
%<< >>=
%p <- seq(from=0.3, to=.4, by=.005)
%@
%
%\begin{center}
%\includegraphics{the_prob_we_are_looking_for.pdf}
%\end{center}
%
%\begin{Exercise}[name=Question]
%If we ran 100,000 simulations for each value of $p$ in 0.300, 0.305,
%\ldots, 0.40, what is the total number of times we should observe 385 in
%the outcome on average (\textit{i.e.}, what is the expected number of
%occurrences of 385 in the 2,100,000 simulations)?
%\par\noindent\textcolor{Blue}{\textbf{Note:} you should not run the
%simulations, only compute the expected numbers.}
%\end{Exercise}
%\begin{Answer}
%<< >>=
%sum(100000 * dbinom(x=385, size=1084, prob=p))
%@
%\end{Answer}
%
%
%\begin{Exercise}[name=Question]
%In the same conditions, how many times would we expect to observe 385 when
%the value of $p$ is in the interval 0.325--0.385?
%\end{Exercise}
%\begin{Answer}
%<< >>=
%sum(100000 * dbinom(x=385, size=1084, prob=seq(from=.325, to=.385, by=.005)))
%@
%\end{Answer}
%
%
%\begin{Exercise}[name=Question]
%From the Bayesian point of view, what is the probability that $p$ is in
%the interval 0.325--0.385 given that we had no prior belief about $p$?
%\end{Exercise}
%\begin{Answer}
%<< >>=
%179.8136 / 184.2043
%@
%\end{Answer}


\section{Conclusions}

We introduced the notion of level of a test. One can make a loose analogy
with judicial systems where people are innocent until they are proven
guilty: this ensures that every convict is a criminal (in theory), but it
says nothing about how many criminals can walk free. Likewise, the level
of a test gives the probability of making an error when the null
hypothesis is true, but it does not say anything about the chance of
making an error when the null hypothesis is false.

Along those lines, it is important to understand that the level is the
probability of rejecting the null hypothesis when it is true. It is
\emph{not} the probability that the null hypothesis is true when we reject
it. Those probabilities can be very different. So if an analyst working at
level 1\% rejects a null hypothesis, one does not know the probability
that it was a mistake. In short, the level is only a way to control one
given type of error in statistical tests, but there are multiple ways to
be wrong.

We have introduced binomial variables as sums over binary events. They
cover a large panel of phenomena in biology, Mendelian genetics being just
one of many. The R functions \texttt{rbinom(...)} and \texttt{dbinom(...)}
allow us to sample binomial variables or to compute their probabilities,
respectively.

We have also introduced the method of estimation by maximum likelihood,
This method is based on the idea that we should choose scenarios where
reality appears as most plausible.

You may wonder what the difference is between accepting the hypothesis $p
= 0.25$, say, versus estimating $p = 0.25$. Without going into details,
accepting $p = 0.25$ merely says that it is possible that $p$ is $0.25$.
It does not exclude every other value. Estimating $p = 0.25$ says that
$0.25$ is the ``best'' value according to some criterion. For instance, we
could estimate $p = 0.28$ and accept $p = 0.25$, meaning that $0.28$ is
our best guess, but $0.25$ is not excluded.

Finally, we started to explore the graphical capabilities of R. Using the
functions \texttt{hist(...)} and \texttt{plot(...)} we were able to
represent whole distributions and curves of interest, respectively. The
graphical toolbox of R is very rich, and those are only some examples of
the possibilities at our disposal.


\bibliography{references}

\cleardoublepage
\shipoutAnswer
\end{document}
