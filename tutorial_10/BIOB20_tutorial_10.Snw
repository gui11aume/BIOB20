\documentclass[a4paper]{article}

% Packages.
\usepackage{amsthm}
\usepackage[answerdelayed]{exercise}
\usepackage[usenames,dvipsnames]{color}

% Bibliography.
\bibliographystyle{abbrv}

% Definitions.
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% Exercise layout.
\renewcommand{\ExerciseHeader}{\par\noindent\textbf{\large
\ExerciseName\ \ExerciseHeaderNB\ExerciseHeaderTitle
\ExerciseHeaderOrigin}\par}

\renewcommand{\AnswerHeader}{\par\noindent\textbf{
Answer to Question \ExerciseHeaderNB}\par}

\setlength{\ExerciseSkipAfter}{3mm}

% Document layout.
\setlength{\oddsidemargin}{18pt}
\setlength{\textwidth}{420pt}
\setlength{\marginparwidth}{0pt}
\setlength{\marginparsep}{0pt}

% Options.
\SweaveOpts{keep.source=TRUE}

\title{Confidence intervals}
\author{}
\date{}


\begin{document}
\maketitle


\section{Overview}

In this chapter we revisit the example of randomized clinical trials and
introduce confidence intervals in this context.


%% The problem %%
\section{The problem}

When we analyzed the results of the clinical trial for the mRNA-1273
vaccine in tutorial 1, we concluded that the vaccine was more efficient
than the placebo, but we did not estimate the efficiency of the vaccine.
In this tutorial, we are going to revisit the results and design
confidence intervals to quantify the uncertainty about our estimate.


\section{Revisiting the mRNA-1273 clinical trial}

In the course of the mRNA-1273 clinical trial, 15210 participants received
the placebo and 15210 participants received the
vaccine~\cite{baden2020efficacy}. In total, 196 participants developed
symptomatic COVID-19, among which 11 patients received the vaccine and 185
received the placebo.

\begin{Exercise}[name=Question]
\label{chi2}
Arrange the data into a $2 \times 2$ contingency table and perform a
$\chi^2$ test using the function \texttt{chisq.test(...)}. What is the
conclusion of the test?
\end{Exercise}
\begin{Answer}
<< >>=
dat <- print(matrix(c(15210-185, 15210-11, 185, 11),
  ncol=2, dimnames=list(c("placebo", "vaccine"), c("C19_no", "C19_yes"))))
chisq.test(dat)
@

The null hypothesis is that the vaccination status has no influence on the
outcome of the disease (the two variables are independent). The p-value is
very small so we reject the null hypothesis and conclude that the
vaccination status has an effect.
\end{Answer}

\begin{Exercise}[name=Question]
\label{fisher}
Using the table you prepared in Question~\ref{chi2}, perform Fisher's
exact test using the function \texttt{fisher.test(...)}. What is the
conclusion of the test?
\end{Exercise}
\begin{Answer}
<< >>=
fisher.test(dat)
@

The null hypothesis is that the vaccination status has no influence on the
outcome of the disease (the two variables are independent, just like in
Question~\ref{chi2}). The p-value is very small so we reject the null
hypothesis and conclude that the vaccination status has an effect.
\end{Answer}


\begin{Exercise}[name=Question]
\label{binom}
Formulate the problem from the point of view of Bernoulli trials. Use the
function \texttt{pbinom(...)} to estimate the p-value (assume that the
test is one-sided for simplicity).
\end{Exercise}
\begin{Answer}
In this framework, we count the number of ``successes'' among 196 trials.
The null hypothesis is that the probability of success is $1/2$. We are
thus interested in the probability of obtaining 11 or fewer successes.
<< >>=
pbinom(size=196, prob=.5, q=11)
@

The p-value is very small so we reject the null hypothesis and we conclude
that participants who received the vaccine are less likely to develop
symptomatic COVID-19 than the participants who received the placebo.
\end{Answer}

We assumed earlier that the organizers initially decided to stop the
clinical trial as soon as 196 participants develop symptomatic COVID-19.
However, there is no mention of this in the methods, so this is probably
not the case. Instead, the organizers may have stopped the trial when they
deemed the number to be sufficiently high.

\begin{Exercise}[name=Question]
One of the tests from Questions~\ref{chi2}, \ref{fisher} and \ref{binom}
is more appropriate than the other two, in the sense that its null
distribution $i$) represents the experimental situation and $ii$) can be
fully computed before the results of the test are available. Which test is
it?
\end{Exercise}
\begin{Answer}
The $\chi^2$ test. Fisher's exact test assumes sampling without
replacement, which amounts to fixing the margins of the contingency table
(the distribution of placebo vs vaccine is fixed but not the distribution
of symptomatic COVID-19). The binomial approach requires knowing that 196
participants developed COVID-19. In some instances of clinical trials,
this is predetermined, but the authors make no mention of this in the
article~\cite{baden2020efficacy}
\end{Answer}


\section{Estimating vaccine efficiency}

The estimated efficiency of the vaccine is defined as $\theta = 1-f$ where
$f$ is the ratio of vaccinated to non-vaccinated participants among those
who develop COVID-19. Here $\theta = 1 - f = 1 - 11/185 = 0.94$ --- note
that with this definition, the efficiency is zero when there are as many
participants who received the vaccine as the placebo among those who
develop COVID-19.

Because of sampling effects, the estimated efficiency always fluctuates
around the true value. It is therefore important to quantify how certain
we are about the estimate. On the one hand, the clinical trial is large
because it involves over 30,000 participants, but on the other hand, the
number of people who developed COVID-19 is much smaller. The vaccine is
more efficient than the placebo, but how sure are we that that efficiency
is high?


\begin{Exercise}[name=Question]
\label{test}
Using a binomial distribution as in Question~\ref{binom}, test the the
null hypothesis that the efficiency of the vaccine is 0.94. Note the
probability of ``success'' of the binomial is $(1-\theta) / (2-\theta)$,
not $1-\theta$ (if the efficiency $\theta$ is 0, then half of the
participants who develop symptomatic COVID-19 are in the vaccinated group
so a correction is necessary).
\end{Exercise}
\begin{Answer}
<< >>=
prob <- print((1-.94) / (2-.94))
pbinom(size=196, prob=prob, q=11)
@

The p-value is large and we accept the null hypothesis that the efficiency
of the vaccine is 0.94.
\end{Answer}


It is not surprising that the new null hypothesis seems to be more
consistent with the data because we used the data to formulate it (0.94 is
the maximum-lieklihood estimate so it would be odd to reject the null
hypothesis here). But it is possible to formulate arbitrary null
hypotheses without data. To demonstrate this let us test whether the
efficiency is 80\%, which is an arbitrary high number.

\begin{Exercise}[name=Question]
Using the same approach as in Question~\ref{test} test the the null
hypothesis that the efficiency of the vaccine is 0.8.
\end{Exercise}
\begin{Answer}
<< >>=
prob <- print((1-.8) / (2-.8))
pbinom(size=196, prob=prob, q=11)
@

The p-value is small and we reject the null hypothesis. We conclude that
the efficiency must be above 80\%.
\end{Answer}


It is important to highlight that accepting a null hypothesis is not a
statement that the null hypothesis is true. Neither is it a statement that
other hypotheses are false. Accepting the null hypothesis means that the
null hypothesis is \emph{compatible} with the observations (or more
accurately \emph{not incompatible} with the observations). So there is no
inconsistency in accepting distinct null hypotheses and we can search
collections of hypotheses that are acceptable.

\begin{Exercise}[name=Question]
\label{pvals}
Using the same approach as in Question~\ref{test}, collect the p-values
associated with efficiencies ranging from 80\% to 100\% by increment of
1\%. For which efficiency in this set is the p-value highest?
\par\noindent\textcolor{Blue}{\textbf{Hint:} Use a for-loop.}
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Input your answer as a
percentage (\textit{i.e.}, a number between 0 and 100).}
\end{Exercise}
\begin{Answer}
<< >>=
eff <- seq(from=.8, to=1, by=.01)
prob <- ((1-eff) / (2-eff))
pvals <- rep(NA, 21)
for (i in 1:21) { pvals[i] <-  pbinom(size=196, prob=prob[i], q=11) }
eff[which.max(pvals)]
@

The highest p-value is reached for efficiency 100\%. Recall that the test
is one-sided for simplicity. We reject the null hypothesis when the true
efficiency is greater than our assumption. When the efficiency is 100\% this
is not possible so the hypothesis is never rejected.
\end{Answer}


\begin{Exercise}[name=Question]
\label{fig}
Plot the p-values from Question~\ref{pvals} against the associated
efficiency.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Upload the figure.}
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
plot(x=eff, y=pvals, type="l", panel.first=grid())
@
\end{Answer}


\begin{Exercise}[name=Question]
\label{95}
What is the range of efficiencies that are associated with a p-value
of 0.05 or higher?
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Input the length of the
interval.}
\end{Exercise}
\begin{Answer}
<< >>=
lower <- print(eff[min(which(pvals >= .05))])
upper <- print(eff[max(which(pvals >= .05))])
@
\end{Answer}


\begin{Exercise}[name=Question]
\label{99}
What is the range of efficiencies that are associated with a p-value
of 0.01 or higher?
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Input the length of the
interval.}
\end{Exercise}
\begin{Answer}
<< >>=
lower <- print(eff[min(which(pvals >= .01))])
upper <- print(eff[max(which(pvals >= .01))])
@
\end{Answer}


\section{Confidence intervals}

\begin{definition}[confidence interval]
A confidence interval is a \emph{procedure} to estimate an unknown
parameter $\theta$ to within an interval. The procedure of a confidence
interval at $x\%$ ensures that for any value of $\theta$, there is an
$x\%$ chance that $\theta$ belongs to the interval.
\end{definition}

Note that the definition does not say that for any observed sample there
is an $x\%$ chance that $\theta$ belongs to the interval. Just like for
statistical tests, the guarantees of accuracy are given to the procedure
but they may not apply in a particular case (and like for statistical
tests, precision can be guaranteed \emph{before} the data is collected).

The intervals of Questions~\ref{95} and \ref{99} are 95\% and 99\%
confidence intervals, respectively. To prove this, say that the true
efficiency of the vaccine is $\theta$. Our procedure is to include
\emph{all} the efficiencies that are associated with a p-value of 0.05 or
higher --- respectively 0.01 or higher. The true value is $\theta$ so
there is a 95\% chance of accepting the null when testing the hypothesis
that the parameter is equal to $\theta$. This in turn implies that there
is a 95\% chance that $\theta$ is included in the set --- respectively
99\%. Note that the other values are irrelevant, we just want some
guarantee that $\theta$ is in the set.

Since we used one-sided tests for simplicity, the intervals of
Questions~\ref{95} and \ref{99} are of the form $\theta \geq \theta^*$,
where $\theta^*$ is a threshold value. The form of the interval is
irrelevant, as long as the true value $\theta$ has a known chance of
belonging to the test before data is collected.

Confidence intervals are widely misinterpreted. A 95\% confidence interval
does not have a 95\% chance of containing the true value of the parameter.
In addition, a confidence interval makes no use of any prior knowledge we
may have about $\theta$. Let us give an example for clarity.

<< echo=FALSE, eval=TRUE >>=
set.seed(71) # Chosen carefully.
@

\begin{Exercise}[name=Question]
\label{wrong}
A parameter \texttt{mu} is created with a 50:50 chance to be -100 or +100.
Then a normal sample with mean \texttt{mu} is drawn.
<< >>=
mu <- sample(c(100,-100), size=1)
rnorm(n=10, mean=mu)
@
From the outcome above, what is the 95\% confidence interval for
\texttt{mu} given by the function \texttt{t.test(...)}?
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Give the lower bound.}
\end{Exercise}
\begin{Answer}
<< >>=
x <- c(100.13857,99.19935,101.61891,101.22346,99.83571,
  100.71183,100.72870,100.76126,100.86302,101.45366)
t.test(x)
@
\end{Answer}


\begin{Exercise}[name=Question]
What is the probability that \texttt{mu} belongs to the confidence
interval of Question~\ref{wrong}?
\end{Exercise}
\begin{Answer}
The interval contains neither -100 nor 100, so it cannot contain
\texttt{mu}. The probability is 0.
\end{Answer}

It is true that 95\% of the confidence intervals at level 95\% contain the
true parameter $\theta$, but the example above shows that this does not
imply that a \emph{given} confidence interval has a 95\% chance of
containing the true parameter $\theta$. It is sometimes possible to update
our knowledge about $\theta$ from the context and the observations.
However, the confidence interval procedure has to remain the same to
maintain the initial guarantees, so the bounds of the confidence interval
cannot be changed, even when they are inadequate in some \emph{given}
instance.

Using one-sided tests is not the standard approach to generating
confidence intervals. This is usually done with two-sided tests.

\begin{Exercise}[name=Question]
Using a binomial distribution as in Question~\ref{binom}, test the the null
hypothesis that the efficiency of the vaccine is 80\%. Assume that the
test is two-sided, so that the p-value is $i$) 2 times the probability of
obtaining a statistic \emph{higher} than the observation if the
observation is above the expected value, or $ii$) 2 times the probability
of obtaining a statistic \emph{lower} than the observation if the
observation is below the expected value.
\end{Exercise}
\begin{Answer}
When the efficiency is 80\%, the expected fraction of vaccinated patients
who develop COVID-19 is $(1 - 0.8) / (2 - 0.8) = 16.7\%$. With 196
participants with COVID-19, the expectation is 32.7. The observed
statistic is below expectation.
<< >>=
prob <- print((1-.8) / (2-.8))
2 * pbinom(size=196, prob=prob, q=11, lower=TRUE)
@
\end{Answer}


\begin{Exercise}[name=Question]
\label{pval2}
Collect the p-values as in Question~\ref{pvals}, but use a two-sided test.
Plot the results as in Question~\ref{fig}.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Upload the figure.}
\end{Exercise}
\begin{Answer}
The observations are below expectation when the efficiency is between 80\%
and 94\%, otherwise they are above expectation. We compute the p-values in
two rounds.
<< fig=TRUE >>=
eff <- seq(from=.8, to=1, by=.01)
prob <- ((1-eff) / (2-eff))
pvals <- rep(NA, 21)
for (i in 1:15) {
  pvals[i] <- 2 * pbinom(size=196, prob=prob[i], q=11, lower=TRUE)
}
for (i in 15:21) {
  # Switch to 10 so that we get the probability of >= 11
  pvals[i] <- 2 * pbinom(size=196, prob=prob[i], q=10, lower=FALSE)
}
plot(x=eff, y=pvals, type="l", panel.first=grid())
@
\end{Answer}


\begin{Exercise}[name=Question]
Give a 95\% confidence interval for the efficiency using the results from
Question~\ref{pval2}.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Give the length of the
interval.}
\end{Exercise}
\begin{Answer}
<< >>=
lower <- print(eff[min(which(pvals >= .05))])
upper <- print(eff[max(which(pvals >= .05))])
@
\end{Answer}


\section{$\chi^2$ confidence intervals (bonus points)}

To compute confidence intervals, we need to compute p-values under a range
of alternative hypotheses. In this particular example, the $\chi^2$ test
is more appropriate than the binomial distribution because the $\chi^2$
distribution of the statistic does not require to know the number of
participants who develop COVID-19. However, it is tedious to compute the
p-value of the $\chi^2$ test under alternative distributions.

For this, we need the non-central $\chi^2$ distribution, which
incorporates a parameter that quantifies the deviation from the null
hypothesis.

\begin{Exercise}[name=Question]
The observed Pearson $\chi^2$ statistic is 155.47. Use the fonction
\texttt{pchisq(..., lower=FALSE)} to compute the $\chi^2$ p-value for
values of the parameter \texttt{ncp} from 0 to 250 by increment of 1.
Here we assume that the test is one-sided. Plot the p-value against the
non-centrality parameter \texttt{ncp}.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} Upload the figure.}
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
ncp <- seq(from=0, to=250, by=1)
pvals <- rep(NA, 251)
for (i in 1:251) { pvals[i] <- pchisq(q=155.47, df=1, ncp=ncp[i], lower=FALSE) }
plot(ncp, pvals, type="l", panel.first=grid())
@
\end{Answer}


The function \texttt{pchisq(...)} is efficient to compute the power of a
$\chi^2$ test or to compute confidence intervals, however, it is not
straightforward to convert the efficiency of the vaccine into a
non-centrality parameter. For this reason, we took an approach based on
the binomial distribution. The distribution may not be exactly appropriate
because we need to know that 196 participants developed COVID-19, but the
interpretation is much simpler in this context.


\section{Conclusions}

We have introduced confidence intervals, with a particular focus on their
generation from basic principles. Confidence intervals are often presented
as standard formulas based on the normal distribution, but they are more
general and they can be used in a wide range of contexts and applications.

To compute confidence intervals, one needs a statistical test from which
the p-values can be computed on a range of hypotheses. Those are exactly
the conditions that are required to compute the power of a test, so they
are available in general.

An $x\%$ confidence interval is computed by collecting all the null
hypotheses that have a p-value above $1-x$. This procedure ensures that
the true hypothesis is included in the set $x\%$ of the time, which is the
definition of a confidence interval.

The confidence is inherently linked to a test, including the statistic,
the assumptions about the distribution and the rejection regions.
Therefore, the guarantees of confidence intervals hold only if a series of
auxiliary hypotheses also hold --- typically, that observations are
independent for instance. When those basic assumptions are violated, the
bounds of the interval may be incorrect.

The most common misinterpretation is that there is an $x\%$ chance that
the parameter of interest is within a given $x\%$ confidence interval.
This may or may not be the case. But in greater generality, this statement
is often meaningless because parameters are not assumed to be random
variables in the frequentist interpretation, so they cannot have a
probability of being in a certain interval. Either they are or they are
not, but this is not random.

Once one accepts that the guarantees of confidence intervals concern the
\emph{procedure} and not the outcome, they become a useful estimation
tool. In the present example, we saw how the allow the analyst to trust
that the efficiency of the mRNA-1273 vaccine was probably above 90\%
against the early variants of the COVID-19 epidemic. One of the most
useful aspects of confidence intervals is to draw the attention on the
magitude of the effects (above 90\% efficiency) instead of the results of
the test (the vaccine is more efficient than the placebo).

It is also important to highlight that an $x\%$ confidence intervals is
strictly equivalent to the result of a test at level $1-x$, while giving
more information. Indeed, if a value of interest is in a confidence
interval, then its associated p-value is above $1-x$ and the associated
null hypothesis is accepted. A common example is whether a confidence
interval for the difference of means intersects 0. If it does, then the
null hypothesis that the two means are equal is accepted, by construction
of the confidence interval.

In sum, confidence intervals are an efficient way to communicate
statistical results, but they are underused because of the exagerated
emphasis on p-values. Analysts who understand them should use them on a
regular basis.



\bibliography{references}

\cleardoublepage
\shipoutAnswer
\end{document}
