\documentclass[a4paper]{article}

% Packages.
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames]{color}
\usepackage[answerdelayed]{exercise}
\usepackage{url}

% Bibliography.
\bibliographystyle{abbrv}

% Definitions.
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% Exercise layout.
\renewcommand{\ExerciseHeader}{\par\noindent\textbf{\large
\ExerciseName\ \ExerciseHeaderNB\ExerciseHeaderTitle
\ExerciseHeaderOrigin}\par}

\renewcommand{\AnswerHeader}{\par\noindent\textbf{
Answer of \ExerciseName\ \ExerciseHeaderNB}\par}

\setlength{\ExerciseSkipAfter}{3mm}

% Document layout.
\setlength{\oddsidemargin}{18pt}
\setlength{\textwidth}{420pt}
\setlength{\marginparwidth}{0pt}
\setlength{\marginparsep}{0pt}

% Options.
\SweaveOpts{keep.source=TRUE}

\title{The binomial distribution}
\author{}
\date{}


\begin{document}
\maketitle

\section{Overview}

In this chapter we introduce the notion of level of a statistical test. We
also explain how to create variables with a binomial distribution and how
to design statistical tests with binomial variables. We use the framework
of formal Mendelian genetics to give an example of application.


\section{The problem}

In 1913, an undergraduate student named Alfred H. Sturtevant published one
of the most influential scientific discoveries in genetics
\cite{sturtevant1913linear}. He was working on fruit flies in the
laboratory of Thomas H. Morgan who had just figured out the rules of
inheritance for genes on the X chromosome.

Back then, scientists knew that genes were on chromosomes, but they had no
idea what they were made of --- the fact that it is DNA would come only in
1944~\cite{avery1944studies}. Yet, Sturtevant found a way to map the genes
relative to each other. It is astonishing that we knew the order of genes
on the chromosomes way before we understood what they were.

The development of statistics came substantially later, so Sturtevant did
not perform tests or investigate the confidence levels of his estimations.
We will use R to view his results in the light of modern statistics.


\section{The binomial distribution}

Fruit flies found in the wild have a black body and red eyes. Sturtevant
had access to mutants with a yellow body or with bright red ``vermilion''
eyes. He knew that the mutated genes were on the X chromosome in both
cases.

We will denote the allele for a black body $b^0$, and the allele for a
yellow body $b^1$. Likewise, we will denote the allele for red eyes $r^0$,
and the allele for vermilion eyes $r^1$. In one of his experiments,
Sturtevant crossed heterozygous females $b^0/b^1$ and looked at the
phenotype of the males in the progeny. Males have only one X chromosome,
which they do not pass to their sons (they pass their Y chromosome
instead), so in this case the genotype of the father is irrelevant. The
alleles on the X chromosome in the male progeny always come from the
mother.

\begin{center}
\includegraphics[width=40mm]{first_cross.pdf}
\end{center}

Among the 1084 males in the progeny of the crosses, 571 were black and 513
were yellow. From this, Sturtevant concluded that males were equally
likely to receive the $b^0$ or the $b^1$ allele from their mother.

To test whether this is indeed the case, we will need a new type of random
variable.

\begin{definition}[binomial distribution]
A binary event has exactly two possible outcomes that are labelled 0 and
1. The binomial distribution describes the total number of 1s in a series
of binary events that are independent and that have the same probability.
The binomial distribution is usually represented by the symbol $B(n,p)$,
where $n$ is the number of events (sometimes referred to as the size) and
$p$ is their probability.
\end{definition}

We will not need the formula, but a variable $X$ follows the binomial
distribution $B(n,p)$ if and only if the probability that $X$ takes the
value $k$ is given by the expression
\begin{equation}
\label{formula}
P(X = k) = \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k} \;\;\; (k=0,1,\ldots, n).
\end{equation}

We are thus interested in generating samples from the distribution
$B(1084, 1/2)$ because there are 1084 events in total and the alleles
$b^0$ and $b^1$ are assumed to have the same probability 1/2.


\begin{Exercise}[name=Question]
Using the documentation if necessary, produce one random number from
$B(1084, 1/2)$ using the function \texttt{rbinom(...)}.
\par\noindent\textcolor{Blue}{\textbf{Note:} the $n$ in $B(n,p)$ is the
parameter \texttt{size} of the \texttt{rbinom(...)} function.}
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
rbinom(n=1, size=1084, prob=1/2)
@
\end{Answer}


\begin{Exercise}[name=Question]
Produce 100,000 random numbers from $B(1084, 1/2)$ using the function
\texttt{rbinom(...)} and compute the average.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
mean(rbinom(n=100000, size=1084, prob=1/2))
@
\end{Answer}


\section{Analyses with one gene}

Now that we can easily produce samples from the target distribution, we
can use a standard statistical analysis to test whether the alleles $b^0$
and $b^1$ are equally probable. To this end, we need
\begin{enumerate}
\item
A null hypothesis.
\item
An alternative  hypothesis.
\item
A protocol to collect data.
\item
A test statistic.
\item
A decision rule.
\end{enumerate}


\begin{Exercise}[name=Question]
What are the null and the alternative hypotheses?
\end{Exercise}
\begin{Answer}
The number of $b^0$ alleles, say, is assumed to be drawn from the binomial
distribution $B(1084, p)$. The null hypothesis is that $p = 1/2$ and the
alternative hypothesis is that $p\neq 1/2$.
\par\noindent\textcolor{Blue}{\textbf{Note:} the alternative is \emph{not}
that the null hypothesis is false. It is more specific.}
\end{Answer}


The protocol to collect the data was given by Sturtevant in
reference~\cite{sturtevant1913linear}. Here we will simply assume that he
followed the principles of unbiased data collection and we will not look
further into this.

\begin{Exercise}[name=Question]
What statistic could we use to distinguish the null from the alternative
hypothesis?
\end{Exercise}
\begin{Answer}
There are many options. If the null hypothesis is true, we expect that
approximately half of the sample should consist of $b^0$ alleles. We will
thus choose the absolute difference to 1084 / 2 = 542.
\end{Answer}


To find a quantitative decision rule, we need to know more about the
distribution of the statistic so that we can have clear expectations.

\begin{Exercise}[name=Question]
Produce a random sample of size 1 from $B(1084, 1/2)$ using the function
\texttt{rbinom(...)} and compute the value of the statistic on this sample
using the function \texttt{abs(...)} to take the absolute value.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
abs(rbinom(n=1, size=1084, prob=1/2) - 542)
@
\end{Answer}


\begin{Exercise}[name=Question]
Produce 100,000 random values of the statistic under the null
distribution. Store them in a variable called \texttt{nulld} (this stands
for ``null distribution''). Use the function \texttt{mean(...)} to compute
the approximate expected value of the statistic under the null hypothesis.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
nulld <- abs(rbinom(n=100000, size=1084, prob=1/2) - 542)
mean(nulld)
@
\end{Answer}


The average gives us an idea of the typical value of the score when the
null hypothesis is true. But to make a decision rule we need to know which
values are atypical, so that we can confidently reject the null hypothesis
when the score is too large to be explained by chance.


\begin{Exercise}[name=Question]
Plot the histogram of the vector \texttt{nulld} using the function
\texttt{hist(...)} with default parameters. What is the range of values
with highest frequency?
\end{Exercise}
\begin{Answer}
The values in 0-5 have highest frequency.
<< fig=TRUE >>=
hist(nulld)
@
\end{Answer}


In order to design formal decision rules, we need to measure risks. One of
the key concepts is the so-called level of a test.

\begin{definition}[level of a statistical test]
The level of a statistical test is the risk of falsely rejecting the null
hypothesis. In other words, it is the probability of rejecting the null
hypothesis when it is true. The level is chosen by the analyst.
\end{definition}

The level is a risk that the analyst is willing to take, so the value is
typically small, like 1\% or so. If the level is chosen by the analyst,
then why not choose a 0\% risk? We will see later, when we discuss the
notion of power of a statistical test, that there is a cost to lowering
the level. Without going into technical considerations, we will set the
level to 1\% for the present analysis.

\begin{Exercise}[name=Question]
What is the cutoff value $x$ such that there is only a 1\% chance that the
statistic is greater than or equal to $x$ when the null hypothesis is
true? Add a red vertical line at this value in the plot of the histogram.
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
quantile(nulld, 0.99)
hist(nulld)
abline(v=quantile(nulld, 0.99), col="red")
@
\end{Answer}


Having chosen a level, we now have a threshold for the decision rule and
we can decide whether we believe the null hypothesis or not.

\begin{Exercise}[name=Question]
Finish the statistical analysis and conclude about the null hypothesis.
\end{Exercise}
\begin{Answer}
The value $x$ at the top 1\% of the null distribution \texttt{nulld} is
approximately 43. This means that if the null hypothesis is true, there is
an approximately 1\% chance that the statistic is below 542 - 43 = 499 or
higher than 542 + 43 = 585. Sturtevant obtained 571 $b^0$ alleles, which
is within the interval 499--585, so there is no reason to reject the null
hypothesis. The results are compatible with expectations.

A more automatic way of concluding is to note that the observed value of
the statistic is $|571 - 542| = 29 < 43$. The value 29 is on the
\emph{left} or the red line in the histogram of the null distribution.
This kind of statement is in general sufficient to accept the null
hypothesis.
\end{Answer}


Sturtevant then focused on the color of the eyes in the same cross. The
females were heterozygous $r^0/r^1$, and once again the genotype of the
fathers was irrelevant because he considered only the males in the
progeny. Sturtevant obtained 574 males with red eyes and 510 males with
vermilion eyes.

\begin{center}
\includegraphics[width=40mm]{second_cross.pdf}
\end{center}

\begin{Exercise}[name=Question]
Perform a similar statistical analysis to decide whether the alleles
$r^0$ and $r^1$ are equally probable.
\end{Exercise}
\begin{Answer}
The null hypothesis, the alternative hypothesis, the data collection
protocol, the statistic and the decision rule are the same. In this case
the null distribution is also the same, so we can conclude directly. The
observed statistic is $|574 - 542| = 32 < 43$ (the value is on the
\emph{left} of the red line in the histogram) so we accept the null
hypothesis.
\end{Answer}


\section{Analyses with two genes}

Sturtevant actually recorded both characters simultaneously for every
male. Out of the 1084 males in the progeny of the cross above, 385 were
black with red eyes ($b^0, r^0$), 186 were black with vermilion eyes
($b^0, r^1$), 189 were yellow with red eyes ($b^1, r^0$) and 324 were
yellow with vermilion eyes ($b^1, r^1$).

\begin{center}
\includegraphics[width=60mm]{third_cross.pdf}
\end{center}

Sturtevant knew that in the 1865 landmark work of Gregor Mendel, it was
shown that characters are inherited
independently~\cite{mendel1866versuche} (an English translation is
available in reference~\cite{mendel1996experiments}). But Gregor Mendel
did not know that genes are on chromosomes and Sturtevant was interested
in testing whether characters were inherted independently even when they
are on the same chromsome.

\begin{definition}[independence]
In statistics, two events are independent if the probability that they
both occur is the product of the probabilities that each one occurs
individually. Mathematically, $A$ and $B$ are two independent events if
and only if  $\text{Prob}(A\cap B) = \text{Prob}(A) \text{Prob}(B)$.
\end{definition}

Since the frequency of the allele $b^0$ is 1/2 and that of the allele
$r^0$ is also 1/2, the frequency of the genotype $b^0, r^0$ should be $1/2
\times 1/2 = 1/4$ if the alleles are inherited independently. In other
words, the number of genotypes $b^0, r^0$ should be distributed as
$B(1084, 1/4)$.


\begin{Exercise}[name=Question]
In this context, what are the null and the alternative hypotheses?
What statistic should we use to discriminate the null from the alternative
hypothesis?
\end{Exercise}
\begin{Answer}
The number of genotypes $b^0, r^0$ is assumed to be drawn from the
binomial distribution $B(1084, p)$. The null hypothesis is that $p = 1/4$
and the alternative hypothesis is that $p\neq 1/4$.

The expected value is no longer 542 but 271. We should now compute the
deviation from 271.
\end{Answer}


\begin{Exercise}[name=Question]
\label{exnulld_pair}
Produce 100,000 random values of the statistic under the null
distribution. Store them in a variable called \texttt{nulld}. Use the
function \texttt{mean(...)} to compute the approximate expected value of
the statistic under the null hypothesis.
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
nulld <- abs(rbinom(n=100000, size=1084, prob=1/4) - 271)
mean(nulld)
@
\end{Answer}


\begin{Exercise}[name=Question]
What is the cutoff value $x$ such that there is only a 1\% chance that the
statistic is greater than or equal to $x$? Add a red vertical line at this
value in the plot of the histogram.
\end{Exercise}
\begin{Answer}
<< >>=
quantile(nulld, 0.99)
hist(nulld)
abline(v=quantile(nulld, 0.99), col="red")
@
\end{Answer}


\begin{Exercise}[name=Question]
Finish the statistical analysis and conclude about the null hypothesis.
\end{Exercise}
\begin{Answer}
The observed statistic is $|385 - 271| = 114 > 36$. This value is higher
than the threshold so we reject the null hypothesis (it is on the
\emph{right} of the red line in the histogram). We conclude that the
probability of ocurrence of $b^0, r^0$ is not 1/4 and the two alleles are
not inherited independently.
\end{Answer}


\section{Estimating the linkage}

Sturtevant went further than observing that genes were not inherited
independently. He also used the probability of association between the
alleles as a distance between the corresponding genes.

In his footsteps, we set out to estimate the probability of occurrence of
the genotype $b^0, r^0$. For this, we can use the maximum likelihood
method, whereby we screen hypotheses and pick the one where the observed
events are the most probable.


\begin{Exercise}[name=Question]
\label{exnulld_pair}
Produce 100,000 random values from the distribution $B(1084, 1/4)$. How
many times does the value 385 appear in the output?
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=1/4) == 385)
@
\end{Answer}


\begin{Exercise}[name=Question]
Repeat the procedure of Question~\ref{exnulld_pair} by setting
\texttt{prob} to 0.30, 0.35, 0.40 and 0.45. Which is the value of
\texttt{prob} such that 385 appears most frequently in the output?
\par\noindent\textcolor{BrickRed}{\textbf{Quercus:} use seed 123 each
time.}
\end{Exercise}
\begin{Answer}
<< >>=
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=0.30) == 385)
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=0.35) == 385)
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=0.40) == 385)
set.seed(123)
sum(rbinom(n=100000, size=1084, prob=0.45) == 385)
# The highest is reached for prob = 0.35.
@
\end{Answer}


We should favor the distribution $B(1084, p)$ where the observed value
(\textit{i.e.}, 385) is as common as possible. Other distributions should
be ignored because the observations would be very unlikely to occur. This
makes sense at an intuitive level, but we have screened only a few values
of $p$. How could we be more thorough?


\begin{Exercise}[name=Question]
The function \texttt{dbinom(...)} gives the probability of observing a
result under a given binomial distribution. It is the numeric application
of equation~(\ref{formula}) (\textit{i.e.}, it is a deterministic function
without random component). Using the documentation if necessary, compute
the probability of observing 385 with the distribution $B(1084, 0.35)$
\end{Exercise}
\begin{Answer}
<< >>=
dbinom(x=385, size=1084, prob=0.35)
@
\end{Answer}


We see that this approach gives almost the same result as the simulations.
The simulations are inexact because of the random sampling, but for
large samples, they approach the correct result. The function
\texttt{dbinom(...)} allows us to compute the probability of interest on a
large set of models.


\begin{Exercise}[name=Question]
The function \texttt{seq(...)} creates a regular sequence of values.
Using the documentation if necessary, create a sequence with values
$0.300, 0.305, 0.3100, \ldots  0.40$. Assign the result to a vector called
\texttt{p}. What is the length of \texttt{p}?
\end{Exercise}
\begin{Answer}
<< >>=
p <- seq(from=0.3, to=.4, by=.005)
length(p)
@
\end{Answer}


\begin{Exercise}[name=Question]
Use the functions \texttt{dbinom(...)} and \texttt{seq(...)} as above to
return the probability of obtaining 385 when $p = 0.300, 0.305, \ldots
0.40$. Assign the results to a variable called \texttt{likelihood}. What
is the maximum value of the vector \texttt{likelihood}?
\end{Exercise}
\begin{Answer}
<< >>=
likelihood <- dbinom(x=385, size=1084, prob=p)
max(likelihood)
@
\end{Answer}


The highest value of the likelihood is of little relevance. What matters
is the value of $p$ for which the maximum is reached. It is interesting to
get the answer graphically. The R programming language makes it easy to
create figures from which further insight can be gained. Run the following
command to plot the likelihood against the value of $p$ in the
distribution $B(1084, p)$.
<< eval=FALSE, echo=TRUE >>=
plot(x=p, y=likelihood, type="l")
@


\begin{Exercise}[name=Question]
What is the maximum likelihood estimate of $p$?
\par\noindent\textcolor{Blue}{\textbf{Note:} you can use the argument
\texttt{panel.first=grid()} in \texttt{plot(...)} for more precision.}
\end{Exercise}
\begin{Answer}
The maximum is reached for $p=0.355$.
<< fig=TRUE >>=
plot(p, likelihood, type="l", panel.first=grid())
@
\end{Answer}


\section{Bonus points: the Bayesian approach}

Plotting the likelihood function brings us one step closer to being able
to comment on the confidence in our estimate $p=0.355$. Indeed, we can see
that the likelihood drops by a factor 10 or more for values outside the
interval 0.325--0.385. This means that the values of $p$ outside this
interval are at least 10 times less likely to produce the observed outcome
385 males with genotype $b^0,r^0$ than $p=0.355$.

But this is not the same as saying that values of $p$ outside the interval
are 10 times less plausible than $p=0.355$. Actually, if you are a
frequentist, this last statement does not mean anything at all because $p$
is not a random variable. It is the unknown linkage between the alleles
$b^0$ and $r^0$, which is a value fixed by nature.

The most intuitive way to quantify the uncertainty about our estimate of
$p$ is to use a Bayesian approach, with the caveat that the answer is
influenced by our prior beliefs. We can say that we had no preconception
and we believed that all the possible values between 0 and 1 were equally
plausible (specifying a prior belief based on the conclusion of Gregor Mendel
that the value is 1/4 turns out to be more difficult).

Once again, it is useful to refer to the graphical representation of the
approach.

\begin{center}
\includegraphics{the_prob_we_are_looking_for.pdf}
\end{center}

\begin{Exercise}[name=Question]
If we ran 100,000 simulations for each value of $p$ in 0.300, 0.305,
\ldots, 0.40, what is the total number of times we should observe 385 in
the outcome on average (\textit{i.e.}, what is the expected number of
occurrences of 385 in the 2,100,000 simulations)?
\par\noindent\textcolor{Blue}{\textbf{Note:} you should not run the
simulations, only compute the expected numbers.}
\end{Exercise}
\begin{Answer}
<< >>=
sum(100000 * dbinom(x=385, size=1084, prob=p))
@
\end{Answer}


\begin{Exercise}[name=Question]
In the same conditions, how many times would we expect to observe 385 when
the value of $p$ is in the interval 0.325--0.385?
\end{Exercise}
\begin{Answer}
<< >>=
sum(100000 * dbinom(x=385, size=1084, prob=seq(from=.325, to=.385, by=.005)))
@
\end{Answer}


\begin{Exercise}[name=Question]
From the Bayesian point of view, what is the probability that $p$ is in
the interval 0.325--0.385 given that we had no prior belief about $p$?
\end{Exercise}
\begin{Answer}
<< >>=
179.8136 / 184.2043
@
\end{Answer}


\section{Conclusions}

The strategy that we referred to as ``statistical analysis'' throughout is
actually a formal statistical test. We introduced the notion of level of a
test, which is reminiscent of the judicial system where one has to decide
whether it worse to condemn an innocent or release a criminal. Likewise,
the level controls the chance of making an error when the null hypothesis
is true, but it does not say anything about the chance of making an error
when the null hypothesis is false (which always increases when the level
is decreased).

Along those lines, it is important to understand that the level is not the
probability that the null hypothesis is true given that it was rejected.
It is the probability that the null hypothesis is rejected given that it
is true. So if an analyst working at level 1\% rejects a null hypothesis,
one does not know the probability that it was a mistake. In short, the
level is only a way to control one type of error in statistical tests, but
there are multiple ways to be wrong.

We have introduced binomial variables as sums over binary events. They
cover a large panel of phenomena in biology, Mendelian genetics being just
one of many. The R functions \texttt{rbinom(...)} and \texttt{dbinom(...)}
allow us to sample binomial variables or to compute their probabilities,
respectively.

We have used the method of estimation by maximum likelihood. This was
particularly relevant when we concluded that $p \neq 1/4$. Accepting the
null hypothesis provides a target value for the parameter under study, but
rejecting the null hypothesis does not, so it can be useful to give an
estimate in this case.

Finally, we started to explore the graphical capabilities of R. Using the
functions \texttt{hist(...)} and \texttt{plot(...)} we were able to
represent whole distributions and curves of interest, respectively. The
graphical toolbox of R is very developed, and those are only some examples
of the possibilities at our disposal.


\bibliography{references}

\cleardoublepage
\shipoutAnswer
\end{document}
