\documentclass[a4paper]{article}

% Packages.
\usepackage{amsthm}
\usepackage[answerdelayed]{exercise}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mhchem}

% Bibliography.
\bibliographystyle{abbrv}

% Definitions.
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% Exercise layout.
\renewcommand{\ExerciseHeader}{\par\noindent\textbf{\large
\ExerciseName\ \ExerciseHeaderNB\ExerciseHeaderTitle
\ExerciseHeaderOrigin}\par}

\renewcommand{\AnswerHeader}{\par\noindent\textbf{
Answer to Question \ExerciseHeaderNB}\par}

\setlength{\ExerciseSkipAfter}{3mm}

% Document layout.
\setlength{\oddsidemargin}{18pt}
\setlength{\textwidth}{420pt}
\setlength{\marginparwidth}{0pt}
\setlength{\marginparsep}{0pt}

% Options.
\SweaveOpts{keep.source=TRUE}

\title{The normal distribution}
\author{}
\date{}


\begin{document}
\maketitle

\section{Overview}

In this chapter we introduce the normal distribution, Student's $t$ test
and the notion of nuisance parameter. We showcase some applications in the
field of proton gradients.


%% The problem %%
\section{The problem}

In 1951, Efraim Racker, a researcher at New York University, discovered
that the energy currency of the cell, ATP, could be generated through the
chemical reactions of glycolysis, whereby phosphate groups were
transferred directly from sugars to ADP~\cite{racker1951mechanism}.

But the majority of ATP is produced through another route called oxidative
phosphorylation (colloquially known as ``breathing''). Researchers set out
to find the chemical reactions that produce ATP during oxidative
phosphorylation but in 1961, Peter Mitchell, a researcher at the
University of Edinburgh suggested that such reactions would never be
found~\cite{mitchell1961coupling}. Instead, he suggested that ATP was
produced by the difference of pH between the mitochondria and the
cytoplasm, assuming that the proton gradient was the fuel for the
reaction.


\section{A question of stoichiometry}

If ATP is produced by a chemical reaction, then it has to respect a
particular stoichiometry. The global equation of oxidative phosphorylation
is \ce{ 6 O2 + C6H12O6 -> 6 CO2 + 6 H2O }, which would have to produce a
fixed amount of ATP molecules. In other words, for every atom of oxygen
(O) that is consumed, a certain amount of phosphorus (P) has to be
incorporated into ATP. Therefore the P/O ratio of the reaction is a
constant.

However, Mitchell observed that the P/O ratio sometimes changed, speaking
against a fixed stoichiometry. The proton gradient hypothesis does not
require any stoichiometry, so it became important to measure P/O ratios as
precisely as possible. It was observed that malonate may modify the P/O
ratio, but the effect was quite small~\cite{hinkle1991mechanistic}, so it
became important to know whether the inhibition was real or not.

Import the data into your R session. It consists of independent
measurements of P/O ratios in the presence of
malonate~\cite{hinkle1991mechanistic}. The P/O ratio without malonate was
previously measured at 1.48.

<< >>=
url <- "https://raw.githubusercontent.com/gui11aume/BIOB20/main/tutorial_05/PO.txt"
PO <- scan(url)
@

\begin{Exercise}[name=Question]
Run the usual checks for imported data. Plot the histogram of \texttt{PO}
with default parameters and add a vertical red line at position 1.48.
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
length(PO)
# The dataset is small, show everything.
PO
hist(PO)
abline(v=1.48, col=2)
@
\end{Answer}


It is difficult to judge whether malonate really modifies the P/O ratio.
We need a model for randomness so that we can build an expectation of the
random spread. The normal distribution is well adapted to model
measurement errors.

\begin{definition}[normal distribution]
The normal or Gaussian distribution describes continuous variables that
are the sum of many small effects. The normal distribution is usually
represented by the symbol $N(\mu, \sigma)$, where $\mu$ is the expected
value and $\sigma$ is the standard deviation. The standard normal
distribution is $N(0,1)$, with mean 0 and standard deviation 1.
\end{definition}

We will not need the formula, but a variable $X$ follows the normal
distribution $N(\mu, \sigma)$ if and only if
\begin{equation}
\label{formula}
P(X \leq x) = \int_{-\infty}^x \frac{1}{\sigma \sqrt{2\pi}}
\exp \left\{ -\frac{(z-\mu)^2}{2\sigma^2} \right\} dz.
\end{equation}


\begin{Exercise}[name=Question]
Use the function \texttt{rnorm(...)} with default parameters to generate a
random sample of size 10,000 from the normal distribution. Plot the
histogram using the function \texttt{hist(...)} with option
\texttt{breaks=80} to make it smoother.
\end{Exercise}
\begin{Answer}
The normal distribution is also referred to as the ``bell curve'' because
of the shape of its histogram.
<< fig=TRUE >>=
set.seed(123)
# The highest graduation on the x-axis is 4.
hist(rnorm(n=10000), breaks=80)
@
\end{Answer}


The function \texttt{rnorm(...)} with default parameters samples from the
standard normal distribution $N(0,1)$. To draw from other normal
distributions, one can use the parameters \texttt{mean} and \texttt{sd} to
set $\mu$ and $\sigma$.

\begin{Exercise}[name=Question]
\label{std}
Set the variable \texttt{mu} to any value except \texttt{0} and the
variable \texttt{sigma} to any value exccept \texttt{1}. Then run the code
below.
<< eval=FALSE, echo=TRUE >>=
set.seed(123)
rnorm(n=5, mean=mu, sd=sigma)
set.seed(123)
mu + sigma * rnorm(n=5)
@
What do you observe and what are the implications?
\end{Exercise}
\begin{Answer}
Let us choose $\mu = 18.27$ and $\sigma = 1.827$.
<< >>=
mu <- 18.27
sigma <- 1.827
set.seed(123)
rnorm(n=5, mean=mu, sd=sigma)
set.seed(123)
mu + sigma * rnorm(n=5)
@
The numbers are exactly identical. This means that the distribution
$N(\mu, \sigma)$ can be obtained from the distribution $N(0,1)$ by
multiplying the results by $\sigma$ and adding $\mu$.
\end{Answer}

It is easy to convert the standard normal distribution into any other
normal distribution: if $X$ has a $N(0,1)$ distribution, then $\sigma X +
\mu$ has a $N(\mu, \sigma)$ distribution. Alternatively, if $X$ has a
$N(\mu, \sigma)$ distribution then $(X - \mu) / \sigma$ has a $N(0,1)$
distribution (\textit{i.e.} a standard normal distribution).

Going back to the biological problem, We can decide whether malonate
changes the P/O ratio with a statistical test. To this end, we need

\begin{enumerate}
\item
A null hypothesis.
\item
An alternative  hypothesis.
\item
A protocol to collect data.
\item
A test statistic.
\item
A decision rule.
\end{enumerate}

\begin{Exercise}[name=Question]
What are the null and the alternative hypotheses?
\end{Exercise}
\begin{Answer}
The null hypothesis is that the measurements of the P/O ratio with
malonate are distributed as $N(\mu, \sigma)$ with $\mu = 1.48$. The
alternative hypothesis is that the distribution is $N(\mu, \sigma)$ with
$\mu \neq 1.48$.
\end{Answer}


The protocol to collect data is very important here because there was a
long controversy as to whether the measurements were accurate. We will
leave this discussion to experts of biochemistry and focus on the
statistic. The mean seems like an obvious choice, so let's try it.

A common approach is to design a statistic that measures the distance to
the target. We therefore need to subtract 1.48 from the mean so that the
statistic is close to 0 if the null hypothesis is true (instead of being
close to 1.48). This practice is even the source of the term ``null''
hypothesis because it has the form ``something is equal to zero'', as in
$\mu - 1.48 = 0$.

It is easy to compute the value of the mean of the sample from which we
subtract 1.48, but it is not possible to derive the distribution of
this statistic. Indeed, to generate random samples we would need to use
the function \texttt{rnorm(...)} without a known value of $\sigma$, like
\texttt{rnorm(n=10000, mu=1.48, sigma=??) - 1.48}


\section{The nuisance parameter}

In the present context, $\sigma$ is called a nuisance parameter. We have
no interest for $\sigma$, but the fact that we do not know its value
prevents us from learning what we want about $\mu$.

There are multiple strategies to deal with nuisance parameters. One method
is to find a statistic with a distribution that does not depend on them.

\begin{Exercise}[name=Question]
Set the variable \texttt{sigma} to any value except 1. Draw a random
sample \texttt{x} with the command \texttt{x <- rnorm(n=11, sd=sigma)} and
compute its standard deviation with \texttt{sd(x)}. Then divide every
value in \texttt{x} by the standard deviation of the sample. What is the
standard deviation of the transformed sample?
\end{Exercise}
\begin{Answer}
<< >>=
sigma <- 1.827
set.seed(123)
x <- rnorm(n=11, sd=sigma)
sd(x) # Not equal to sigma because of random sampling.
sd(x / sd(x)) # Always equal to 1.
@
\end{Answer}


Dividing a sample by its standard deviation may remove the dependence on
the nuisance parameter $\sigma$. To obtain a statistic, we still need to
take the average, but this turns out to be more challenging than expected.

\begin{Exercise}[name=Question]
Generate a random sample using \texttt{rnorm(n=11, mean=1.48, sd=sigma)},
subtract 1.48, divide by the standard deviation and compute the mean of
the result. Why can't we use the function \texttt{replicate(...)} to
generate additional values using the same process?
\end{Exercise}
\begin{Answer}
<< >>=
sigma <- 1.827
set.seed(123)
x <- rnorm(n=11, mean=1.48, sd=sigma) - 1.48
mean(x / sd(x))
@
The difficulty is that we have to apply the functions \texttt{mean(...)}
and \texttt{sd(...)} to the \emph{same} sample. The command
\texttt{mean(rnorm(n=11, sd=sigma)) / sd(rnorm(n=11, sd=sigma))} generates
two independent samples so it is not clear how to write a statement with
\texttt{replicate(...)} that would have the desired effect.
\end{Answer}


The R programming language allows us to create our own functions, which is
very useful for such cases (and more generally to use the same code
multiple times). The following example shows the syntax to compute the
square of the input by defining the function \texttt{square(...)}.
<< >>=
square <- function(x) { x^2 }
square(1:4)
@

Similarly, we define a function \texttt{statistic(...)} to subtract 1.48
from all the values of the input, then divide them by their own standard
deviation and finally compute the mean.

<< >>=
statistic <- function(x) { mean((x - 1.48) / sd(x)) }
@


\begin{Exercise}[name=Question]
Use the functions \texttt{statistic(...)} and \texttt{replicate(...)} to
generate 10,000 samples from \texttt{rnorm(n=11, mean=1.48, sd=sigma)}, on
which you compute the statistic. Set \texttt{sigma} to different values
and plot the histogram every time, using options \texttt{xlim=c(-2,2)} and
\texttt{breaks=80}. What do you observe?
\end{Exercise}
\begin{Answer}
Changing \texttt{sigma} does not change the distribution.
<< fig=TRUE >>=
set.seed(123)
sigma <- 1.827
hist(replicate(n=10000, expr=statistic(rnorm(n=11, mean=1.48, sd=sigma))),
   breaks=80, main="", xlab="Statistic (sigma=1.827)", xlim=c(-2,2))
@
<< fig=TRUE >>=
set.seed(123)
sigma <- 1827
hist(replicate(n=10000, expr=statistic(rnorm(n=11, mean=1.48, sd=sigma))),
   breaks=80, main="", xlab="Statistic (sigma=1827)", xlim=c(-2,2))
@
\end{Answer}


\section{Heavy tails}

The statistic we came up with in the previous section is called the
``effect size''. The distribution of the effect size looks Gaussian but it
is not.


If $\sigma$ were \emph{known} to be equal to a value such as 1.827, we
could divide by \texttt{sigma} instead of \texttt{sd(x)} in the
computation of the statistic. We could evaluate the probability that the
statistic is lower than -1 or greater than 1 (\textit{i.e.}, the
probability that it is greater than 1 in absolute value) as shown below.

<< >>=
set.seed(123)
sigma <- 1.827
y <- replicate(n=10000, expr=mean((rnorm(n=11, mean=1.48, sd=sigma)-1.48) / sigma))
mean(abs(y) > 1)
@

For comparison, let us compute this probability when the value of $\sigma$
is unknown and must be estimated with \texttt{sd(x)}.

\begin{Exercise}[name=Question]
\label{student}
Generate a random sample of size 10,000 from the null distribution and
use it to estimate the probability that the statistic is lower than -1 or
greater than 1 (\textit{i.e.}, use it to estimate the probability that it
is greater than 1 in absolute value).
\end{Exercise}
\begin{Answer}
% 1%-99% quantiles from 1000 replications: 0.0058--0.0099
<< >>=
set.seed(123)
sigma <- 1.827
nulld <- replicate(n=10000, expr=statistic(rnorm(n=11, mean=1.48, sd=sigma)))
mean(abs(nulld) > 1)
@
\end{Answer}


\begin{definition}[tails of a distribution]
The tails of a distribution are the probabilities of the inifinite
intervals of the form $(-\infty,x)$ for the left tail, and $(x,+\infty)$
for the right tail.
\end{definition}

Occasionally, \texttt{sd(x)} underestimates the standard deviation by an
order of magnitude (when the points in the sample randomly happen to be
very close to each other). In this case, the expression \texttt{mean(x /
sd(x))} will tend to blow up because it is divided by a tiny number, and
the statistic will be very large (positive or negative). Such large
fluctuations are usually referred to as ``heavy tails''.

Here, the division by \texttt{sd(x)} is responsible for the heavy tails of
the null distribution. The mean has a normal distribution, but dividing it
by \texttt{sd(x)} transforms it into a so-called Student's $t$ variable.
The Student distribution has a bell shape but unlike the normal
distribution, it has heavy tails.

\begin{center}
\includegraphics[width=63mm]{heavy_tails.pdf}
\end{center}

Defining the threshold or the p-value is usually based on the tails of the
null distribution, so it is important to have the right model, otherwise
the thresohld can be misplaced.


\begin{Exercise}[name=Question]
Using the sample created at Question~\ref{student}, find
the threshold at level 1\% (for the absolute value of the statistic).
\end{Exercise}
\begin{Answer}
% 1%-99% quantiles from 1000 replications: 0.917--0.997
<< >>=
quantile(abs(nulld), 0.99)
@
\end{Answer}

We successfully eliminated the nuisance parameter $\sigma$ by desiging a
statistic with a distribution that depends on $\mu$ but not on $\sigma$.
The distribution of the statistic has heavy tails, meaning that it
occasionally produces very large values (positive or negative). We are
almost ready to conclude, but we still need to address the question of the
decision rule.

Here we need to revisit the alternative hypothesis and be sure of what we
want. Any departure from $\mu = 1.48$ is sufficient to reject the null
hypothesis and to conclude that the P/O ratio is not fixed by
stoichiometry. So there are two ways for the null hypothesis to fail:
either because the observed statistic is ``too high'' or because it is
``too low''.

The simplest way to achieve this is to take the absolute value of the
statistic, rejecting the null hypothesis when the obtained value is large.
For a statistic $T$, rejecting the null hypothesis when $T < -t$ or when
$T > t$ is equivalent to rejecting the null hypothesis when $|T| > t$.

\begin{Exercise}[name=Question]
\label{fini}
Finish the statistical test and conclude. For this, generate a sample of
size 10,000 from the distribution of the absolute statistic
(\textit{i.e.}, compute the distribution of its absolute value), plot the
histogram with default parameters, indicate the threshold at level 1\% and
the value of the observed statistic with vertical lines. Give your answer
in the form of a p-value.
\end{Exercise}
\begin{Answer}
% 1%-99% quantiles from 1000 replications: 0.0039--0.0074
<< fig=TRUE >>=
set.seed(123)
# Keep default sd=1 as sigma does not matter.
nulld <- replicate(n=10000, expr=abs(statistic(rnorm(n=11, mean=1.48))))
hist(nulld, breaks=80)
# Threshold with a red line.
abline(v=quantile(nulld, .99), col=2)
obs <- print(abs(statistic(PO)))
# Observed statistic with a blue line.
abline(v=obs, col=4)
# Empirical p-value
mean(nulld >= obs)
@

The observed statistic is above the threshold or (equivalently) the
p-value is below 1\% so we reject the null hypothesis.
\end{Answer}


\section{Type II errors}

There are two ways to be wrong when performing a statistical test. The
first is to reject the null hypothesis when it is true, and the second is
to accept it when it is false. Those are called type I and type II errors,
respectively. The level of a test is the probability of a type I error.
Now, what is the probability of a type II error?

There are multiple answers to this question because there are multiple
ways for the null hypothesis to be false. In our case, we are interested
in whether $\mu$ equals $1.48$, so the probability of a type II error
depends on the value of $\mu \neq 1.48$.

\begin{Exercise}[name=Question]
Assume $\mu = 1.48 + \sigma$ and therefore that the null hypothesis is
false. Set the variable \texttt{sigma} to any value and draw a random
sample of the statistic (from a population of 11 measurements) in these
conditions. Reset the random seed and change the value of \texttt{sigma}.
Does the value of \texttt{sigma} have any influence?
\end{Exercise}
\begin{Answer}
The value of  \texttt{sigma} has no influence.
<< >>=
sigma <- 1.827
set.seed(123)
statistic(rnorm(n=11, mean=1.48 + sigma, sd=sigma))
sigma <- 182.7
set.seed(123)
statistic(rnorm(n=11, mean=1.48 + sigma, sd=sigma))
@
\end{Answer}


\begin{Exercise}[name=Question]
Using \texttt{replicate(...)}, generate 10,000 random values of the
statistic when $\mu = 1.48 + \sigma$. Take the absolute value and plot the
histogram using default parameters.
\end{Exercise}
\begin{Answer}
<< fig=TRUE >>=
sigma <- 1.827
mu <- 1.48 + sigma
set.seed(123)
altd <- replicate(n=10000, expr=abs(statistic(rnorm(n=11, mean=mu, sd=sigma))))
hist(altd, breaks=80)
@

This histogram is different (it is right-skewed in comparison to the null
distribution).
\end{Answer}


\begin{Exercise}[name=Question]
\label{t}
Call $t$ the threshold at level 1\% taken from the null distribution at
Question~\ref{fini}. Compute the probability that the statistic is greater
than or equal to $t$ when $\mu = 1.48 + \sigma$? Is this probability
greater or smaller than when $\mu = 1.48$ (\textit{i.e.}, when the null
hypothesis is true)?
\end{Exercise}
\begin{Answer}
% 1%-99% quantiles from 1000 replications: 0.5401--0.5631
<< >>=
t <- print(quantile(nulld, .99))
mean(altd >= t)
@
When the null hypothesis is true, the probability that the statistic is
greater than $t$ is 0.01 by definition of $t$. Here the probability of
rejecting the null hypothesis is greater than 1\%.
\end{Answer}


\begin{Exercise}[name=Question]
Based on your answer at Question~\ref{t}, give an estimation of the
probability of a type II error when $\mu = 1.48 + \sigma$.
\end{Exercise}
\begin{Answer}
The probability of rejecting the null hypothesis is approximately 0.554
when $\mu = 1.48 + \sigma$, therefore the probability of failing to reject
it is $1 - 0.554 = 0.446$ (remember that $\mu \neq 1.48$, so the null
hypothesis is false and accepting it is a mistake).
\end{Answer}


It is interesting to know the values of $\mu$ for which we are almost
guaranteed to reject the null hypothesis. This gives some idea of the
sensitivity of the statistical test.

\begin{Exercise}[name=Question]
Set $\mu$ to $1.48 + 2\sigma, 1.48 + 3\sigma, \ldots$ and keep computing
the probability of rejecting the null hypothesis. What is the smallest
value for which this probability is 99\% or greater? Call it $1.48 +
k\sigma$. Estimate the relative variation \texttt{k * sd(PO) / 1.48} (this
is the deviation from 1.48 that our test is almost certain to identify as
``not due to chance'').
\end{Exercise}
\begin{Answer}
For $\mu = 1.48 + 2\sigma$ the probability of rejecting the null
hypothesis is already higher than 99\%.
<< >>=
sigma <- 1.827
mu <- 1.48 + 2*sigma
set.seed(123)
altd <- replicate(n=10000, expr=abs(statistic(rnorm(n=11, mean=mu, sd=sigma))))
mean(altd >= t)
2*sd(PO) / 1.48
@
We are almost certain to reject the null hypothesis if $\mu$ is $\approx
13\%$ larger or smaller than the target value 1.48.
\end{Answer}


This example shows that computing the probability of a type II error is
more difficult than computing the probability of a type I error. Also, the
level or risk of type I error is chosen by the analyst, but not the risk
of a type II error. Some statistical tests are better than others in the
sense that they provide a smaller risk of type II error for the same risk
of type I error. This depends on the statistic that we choose, which is
why this step is critical for the design of a test.


\section{Bonus points: one-sided vs two-sided tests}

Here we have performed a two-sided test because the alternative hypothesis
specifies that $\mu$ can be higher or lower than the target value 1.48.

\begin{definition}[two-sided and one-sided tests]
A two-sided test is a statistical test whereby the rejection region is split
into two separate intervals. In other words, if $T$ is the statistic of
the test, the null distribution is rejected if $T < t_L$ or if $T > t_R$,
where $t_L$ and $t_R$ are threshold values. If the rejection region is of
the form $T < t_L$ or is of the form $T > t_R$, then the test is
one-sided.
\end{definition}

\begin{center}
\includegraphics[width=133mm]{two_tails.pdf}
\end{center}

It is interesting to represent the distribution of the original statistic
without taking the absolute value. In this case, the rejection region is
split into two halves on both tails of the distribution. It is customary
to choose the regions such that they each contribute half of the risk of
type I error (\textit{i.e.}, the probability of each region is half of the
level).

\begin{Exercise}[name=Question]
Generate a sample of size 10,000 from the null distribution without taking
the absolute value, plot the histogram with default parameters, indicate
the thresholds at (total) level 1\% and the value of the observed
statistic with vertical lines. What is the length of the acceptance
region?
\end{Exercise}
\begin{Answer}
% 1%-99% quantiles from 1000 replications: 1.8312--1.9849
<< fig=TRUE >>=
set.seed(123)
nulld <- replicate(n=10000, expr=statistic(rnorm(n=11, mean=1.48)))
hist(nulld, breaks=80)
left_threshold <- print(quantile(nulld, .005))
right_threshold <- print(quantile(nulld, .995))
# Thresholds with a red line.
abline(v=left_threshold, col=2)
abline(v=right_threshold, col=2)
obs <- print(statistic(PO))
# Observed statistic with a blue line.
abline(v=obs, col=4)
# Length of the acceptance region.
as.vector(right_threshold - left_threshold)
@
\end{Answer}


There are cases that the null distribution should be accepted even if the
observed statistic is far from the expected value, provided it is on the
side that ``does not matter'', as defined by the analyst. Such cases are
exceedingly rare in natural sciences (and I am often suspicious of their
use), but they are not uncommon in medicine or in business.

Remember that the purpose of a statistical test is to make a decision, not
to know the value of a parameter (this is estimation). There are many
cases where the value of a parameter is advantageous for the decision
maker if it is low and disadvantageous if it is high. In such cases, the
rejection region should be on one side only (the one that minimizes the
risk from the point of view of the decision maker).

\begin{Exercise}[name=Question]
A physician has to decide whether or not to give a cancer patient a
certain treatment. The treatment will succeed only if enzyme X is
sufficiently abundant in the tumor to metabolize the active compound,
otherwise, the treatment will only shorten the life of the patient. Given
the importance of the decision, the biopsy is sent to three independent
laboratories returning dosages of 1.75, 1.82 and 1.46 units. It has been
established that the treatment works only if the concentration of enzyme X
in the tumor is above 1.48. Perform a statistical test at level 1\% using
the statistic that we defined with the function \texttt{statistic(...)}.
Give your answer in the form of a p-value.
\end{Exercise}
\begin{Answer}
Call $\mu$ the concentration of enzyme X in the tumor of the patient. We
can use the limit case $\mu = 1.48$ as a null hypothesis, reject it if we
find out that $\mu > 1.48$ but accept it in case $\mu < 1.48$. This is in
effect equivalent to testing $\mu \leq 1.48$ versus $\mu > 1.48$.

If the observed statistic is far from the expected value but on the
\emph{left} side, then we accept the null hypothesis (we do not treat the
patients because we believe that this will be harmful). If the observed
statistic is on the right side, we reject the null hypothesis (we treat
the patient because we believe that this will be beneficial). Since we
must reject the null hypothesis 1\% of the time when it is true
(\textit{i.e.}, when $\mu = 1.48$), then the threshold must be the
quantile 0.99, even if we do not take the absolute value.
% 1%-99% quantiles from 1000 replications: 0.0584--0.0697
<< fig=TRUE >>=
set.seed(123)
nulld <- replicate(n=10000, expr=statistic(rnorm(n=3, mean=1.48)))
hist(nulld, breaks=80)
threshold <- print(quantile(nulld, .99))
# Thresholds with a red line.
abline(v=threshold, col=2)
obs <- print(statistic(c(1.75, 1.82, 1.53)))
# Observed statistic with a blue line.
abline(v=obs, col=4)
# And the p-value.
mean(nulld >= obs)
@
\end{Answer}


\section{Conclusions}

Peter Mitchell is considered to be a visionary. His theory that ATP is
created by a proton gradient through the membrane of the mitochondrion is
now fully accepted, even though there was initially little experimental
support for it~\cite{mitchell1961coupling}.

We have covered the most important ideas of Students's $t$ test, whereby
we get rid of the nuisance parameter $\sigma$ by using another statistic
than the average. Without this, it would be impossible to learn anything
useful about the parameter of interest $\mu$ because we would not be able
to generate random samples.

This statistic is called the effect size and it involves dividing the
average by the standard deviation. This gives a number without unit
expressing how large the average is relative to the standard deviation, or
how large the difference between the average and a certain value is
relative to the standard deviation.

The distribution of the effect size is bell-shaped but it is not Gaussian.
This distribution is the Student's $t$ distribution, characterized by its
heavy tails that tend to produce occasional outliers. The smaller the
sample size, the heavier the tails and the more common the outliers.

We have introduced the notion of type II error, whereby the analyst
accepts the null hypothesis when it is false. There are many ways for the
null hypothesis to be false, so the risk of type II error is a function
and not a fixed number, which makes it hard to compute. The risk of type
II errors is what characterizes a test and allows a statistician to favor
a test over another one. The risk of a type II error is determined by the
level (\textit{i.e.}, the risk of type I error) and by the statistic of
the test.

Like the mean, the effect size can be positive or negative, which raises
the question whether the test should be one-sided or two-sided. In
general, the test should be two-sided except when the risk for the analyst
lies only on one side of the distribution.

\bibliography{references}

\cleardoublepage
\shipoutAnswer
\end{document}
